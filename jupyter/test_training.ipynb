{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 21:55:57.065725: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-28 21:55:58.313018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> UID of this run: 230728-215600--PeopL\n",
      "run_number : 0\n",
      "Directory /import/home2/yhchenmath/Log/CellSeg/SCS/UNDEFINED/0 exists, please choose an option:\n",
      "Old files deleted.\n",
      "======> Directory for this run: /import/home2/yhchenmath/Log/CellSeg/SCS/UNDEFINED/0\n",
      "2023-07-28 21:56:02,545 INFO Opts: Namespace(dataset={'name': 'scs_mouse_brain', 'loc': 'SCS', 'patch_size': 1200, 'bin_size': 3, 'n_neighbor': 50, 'max_patch_num': 1}, model={'name': 'scs', 'use_amp': False, 'use_sam': False, 'arch': {'class_num': 16, 'input_shape': 2000, 'input_position_shape': 2, 'projection_dim': 64, 'num_heads': 1, 'transformer_units': 128, 'transformer_layers': 8, 'mlp_head_units': [1024, 256]}, 'optimizer': {'name': 'adamw', 'lr': 0.001, 'weight_decay': 0.0001}, 'schedulers': None}, training={'num_epochs': 1, 'batch_size': 10}, gpu='0', code_dir='./', data_dir='/import/home2/yhchenmath/Dataset/CellSeg', log_dir='/import/home2/yhchenmath/Log/CellSeg', exp_name='SCS', run_name='UNDEFINED', run_number='0', seed=0, option_for_existing_dir=None, load_json=True, json_path='./configs/mouse_adult_brain.json', mode='train', uid='230728-215600--PeopL')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('/import/home2/yhchenmath/Code/CellSegmentation/')\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.scs import dir_to_class\n",
    "import torch\n",
    "from options import Options, HParams\n",
    "from utils.experiman import ExperiMan\n",
    "from data import find_dataset_using_name\n",
    "\n",
    "manager = ExperiMan(name='default')\n",
    "parser = manager.get_basic_arg_parser()\n",
    "opt = Options(parser).parse()  # get training options\n",
    "\n",
    "manager.setup(opt)\n",
    "opt = HParams(**vars(opt))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-28 21:56:29,338 INFO ======> Single GPU Training\n",
      "|-----> Constructing count matrices.\n",
      "|-----> <insert> __type to uns in AnnData Object.\n",
      "|-----> <insert> pp to uns in AnnData Object.\n",
      "|-----> <insert> spatial to uns in AnnData Object.\n",
      "2023-07-28 21:57:57,804 INFO ======> 108 patches will be processed.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <select> unspliced layer in AnnData Object\n",
      "|-----> Refining alignment in rigid mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss nan: 100%|████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> Transforming layers ['stain']\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <insert> stain to layers in AnnData Object.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> Constructing nuclei mask from staining image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After discretization into bins, the input image has only 1 different values. It cannot be thresholded in 4 classes. If there are more unique values before discretization, try increasing the number of bins (`nbins`).\n",
      "2023-07-28 21:58:05,720 INFO ======> Patch 0:0 failed. This could be due to no nuclei detected by Watershed or too few RNAs in the patch.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <select> unspliced layer in AnnData Object\n",
      "|-----> Refining alignment in rigid mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss nan: 100%|████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> Transforming layers ['stain']\n",
      "|-----> <select> stain layer in AnnData Object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> <insert> stain to layers in AnnData Object.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> Constructing nuclei mask from staining image.\n",
      "After discretization into bins, the input image has only 1 different values. It cannot be thresholded in 4 classes. If there are more unique values before discretization, try increasing the number of bins (`nbins`).\n",
      "2023-07-28 21:58:09,973 INFO ======> Patch 0:1200 failed. This could be due to no nuclei detected by Watershed or too few RNAs in the patch.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <select> unspliced layer in AnnData Object\n",
      "|-----> Refining alignment in rigid mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss -6.8406e-05: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> Transforming layers ['stain']\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <insert> stain to layers in AnnData Object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> Constructing nuclei mask from staining image.\n",
      "|-----> <insert> stain_mask to layers in AnnData Object.\n",
      "|-----> <select> stain_mask layer in AnnData Object\n",
      "|-----> Finding peaks with minimum distance 7.\n",
      "|-----> <insert> stain_distances to layers in AnnData Object.\n",
      "|-----> <insert> stain_markers to layers in AnnData Object.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <select> stain_mask layer in AnnData Object\n",
      "|-----> <select> stain_markers layer in AnnData Object\n",
      "|-----> Running Watershed.\n",
      "|-----> <insert> watershed_labels to layers in AnnData Object.\n",
      "need at least one array to concatenate\n",
      "2023-07-28 22:01:09,802 INFO ======> Patch 0:2400 failed. This could be due to no nuclei detected by Watershed or too few RNAs in the patch.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <select> unspliced layer in AnnData Object\n",
      "|-----> Refining alignment in rigid mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss -8.0147e-03: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> Transforming layers ['stain']\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <insert> stain to layers in AnnData Object.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> Constructing nuclei mask from staining image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> <insert> stain_mask to layers in AnnData Object.\n",
      "|-----> <select> stain_mask layer in AnnData Object\n",
      "|-----> Finding peaks with minimum distance 7.\n",
      "|-----> <insert> stain_distances to layers in AnnData Object.\n",
      "|-----> <insert> stain_markers to layers in AnnData Object.\n",
      "|-----> <select> stain layer in AnnData Object\n",
      "|-----> <select> stain_mask layer in AnnData Object\n",
      "|-----> <select> stain_markers layer in AnnData Object\n",
      "|-----> Running Watershed.\n",
      "|-----> <insert> watershed_labels to layers in AnnData Object.\n",
      "2023-07-28 22:05:38,213 INFO ======> dataset [SCSMouseBrainDataset] was created\n",
      "2023-07-28 22:05:38,218 INFO ======> length of dataset: 1\n",
      "2023-07-28 22:05:38,219 INFO ======> Model: scs\n",
      "2023-07-28 22:05:38,227 INFO ======> creating model\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"CPU training is not allowed.\"\n",
    "logger = manager.get_logger()\n",
    "logger.info(f\"======> Single GPU Training\")\n",
    "# Set up tensorboard\n",
    "manager._third_party_tools = ('tensorboard',)\n",
    "manager._setup_third_party_tools()\n",
    "\n",
    "# Create dataset\n",
    "dataset_all_patches = find_dataset_using_name(dataset_name=opt.dataset.name)(opt, manager)\n",
    "logger.info(\"======> dataset [%s] was created\" % type(dataset_all_patches).__name__)\n",
    "logger.info(f\"======> length of dataset: {len(dataset_all_patches)}\")\n",
    "\n",
    "# Method\n",
    "logger.info(f\"======> Model: \"+ opt.model.name)\n",
    "if opt.model.name == \"scs\":\n",
    "    from models.scs_model import SCSModel as Model\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "logger.info(f\"======> creating model\")\n",
    "model = Model(\n",
    "    opt = opt,\n",
    "    manager = manager,\n",
    "    dataloader = None\n",
    ").cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "per_patch_dataset = dataset_all_patches[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "per_patch_loader = DataLoader(\n",
    "    per_patch_dataset,\n",
    "    batch_size = opt.training.batch_size,\n",
    "    num_workers = 1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for x_train, x_train_pos, y_train, y_binary_train in per_patch_loader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 50, 2000])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 9188, 2])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
